# ITRI_616_Project

# Telco Customer Churn Prediction

This repository contains the full implementation of a machine learning classification project for the **ITRI616 ‚Äì Artificial Intelligence 1** module at North-West University. The objective is to predict whether a customer will churn based on their demographic, billing, and service usage information.

## üìÅ Project Structure

## üìä Dataset

- **Source**: [Kaggle - Telco Customer Churn](https://www.kaggle.com/datasets/blastchar/telco-customer-churn)
- **Observations**: 7,043
- **Target Variable**: `Churn` (Yes/No)

## üìå Project Goals

- Conduct preprocessing (cleaning, encoding, scaling)
- Train and evaluate multiple ML models
- Compare model performance using key metrics
- Document methodology and results in a structured report

## üß™ Models Used

- Decision Tree
- Random Forest
- Support Vector Machine (SVM)

## üìà Evaluation Metrics

- Accuracy
- Precision
- Recall
- F1 Score
- ROC-AUC

## ‚öôÔ∏è Environment Setup

```bash
pip install -r environment/requirements.txt

Or you can use the following guide

##How To Run Or Use The Notebook In Kaggle##

1. The dataset was chosen from kaggle and therefore used to create a new notebook.
2. After typing in telco customer churn in the search bar on the kaggle website it should appear at the bottom along with similar results.
3. You then choose telco customer churn and select create new notebook, this can be selected by the 3 dots in the right hand corner.
4. If after selecting the dataset you are asked to choose a programming language select python from the dropdown menu then select notebook before clicking create 
new notebook.
5. The notebook should open in jupyter using python 3 as the environment you can then run the dataset by clicking run or run all.
6. This imports the libraries needed to view output and run code.
7. Add code to ensure that the dataset can be read and then import any libraries that you wish to use depending on the code you would like to implement as input
for the dataset. Such examples include:

pandas
numpy
matplotlib
seaborn
scikit-learn
jupyterlab

8. After adding the required input run the commands or code to see what output can be generated and have try different things to see different outputs just to 
explore. Basically have fun with it.
9. The dataset should include code for splitting the training of the model as well as the training itself and some code for cleaning or reviewing the data 
processing of the dataset.
10. When done save the notebook and download it and save different versions or commits to ensure that you track your progress.
11. After saving the notebook you can download it and manually upload it to your github if desired or you can use the option after selcting file to import the 
notebook.
12. This is followed by typing in the required repository you would like to link it to and then importing the notebook.
13. You can also just click link to github and add your credentials follwed by giving your authorization in order to link the notebook to your github.

The link for the repo is given below:
https://github.com/Kristen785/ITRI_616_Project

